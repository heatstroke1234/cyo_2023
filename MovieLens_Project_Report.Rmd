---
title: "MovieLens Project Report"
author: "Nikhil Venkatachalam"
date: "`r format(Sys.time(), '%B %d, %Y')`"
header-includes:
   - \usepackage[default]{sourcesanspro}
   - \usepackage[T1]{fontenc}
mainfont: SourceSansPro
output: pdf_document
always_allow_html: true
---
# Introduction
The goal of this project was to make a movie recommendation software utilizing
machine learning algorithms. Specifically, the movie recommendation software
must have aspired to a certain level of quality and accuracy. This level was
measured by the RMSE (Root Mean Square Error), where a lower RMSE would be 
ideal. The RMSE goal set was 0.86490, so achieving less than this number would
have been the target. This was accomplished by initially engaging in data
exploration (i.e. visualizing the data and outputting its summary statistics),
then moving on to actually training the data by first accounting for
various biases in the rating of various movies, then using machine learning
techniques to further decrease the RMSE and make the movie recommendation
software optimal.

## Initial Setup
This project utilized a dataset collected and provided by GroupLens, a research
lab at the University of Minnesota specializing in recommender systems, among
other things. As such, GroupLens has collected millions of movie reviews,
offering these reviews in the form of datasets of various sizes. For this
project, the 10M dataset was used, and was loaded as follows:

```{r}
if(!require(tidyverse)) install.packages("tidyverse", 
                                         repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", 
                                     repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

options(timeout = 120)

dl <- "ml-10M100K.zip"
if(!file.exists(dl))
  download.file("https://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings_file <- "ml-10M100K/ratings.dat"
if(!file.exists(ratings_file))
  unzip(dl, ratings_file)

movies_file <- "ml-10M100K/movies.dat"
if(!file.exists(movies_file))
  unzip(dl, movies_file)

ratings <- as.data.frame(str_split(read_lines(ratings_file), fixed("::"), 
                                   simplify = TRUE), stringsAsFactors = FALSE)
colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
ratings <- ratings %>%
  mutate(userId = as.integer(userId),
         movieId = as.integer(movieId),
         rating = as.numeric(rating),
         timestamp = as.integer(timestamp))

movies <- as.data.frame(str_split(read_lines(movies_file), fixed("::"), 
                                  simplify = TRUE), stringsAsFactors = FALSE)
colnames(movies) <- c("movieId", "title", "genres")
movies <- movies %>% mutate(movieId = as.integer(movieId))

movielens <- left_join(ratings, movies, by = "movieId")

# Final hold-out test set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding") # using R 3.6 or later
test_index <- createDataPartition(y = movielens$rating, times = 1, 
                                  p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in final hold-out test set are also in edx set
final_holdout_test <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from final hold-out test set back into edx set
removed <- anti_join(temp, final_holdout_test)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)
```

## Dividing the Algorithm
As can be observed, the 10M dataset was divided into two separate datasets, 
those being edx and final_holdout_test. Then, the edx dataset was further split 
into two datasets in order to properly build and test the machine learning 
algorithm. However, the final test was conducted using the final_holdout_test
dataset.

```{r}
# Further division of edx into training and testing sets
set.seed(1, sample.kind = "Rounding") # using R 3.6 or later
test_index <- createDataPartition(y = edx$rating, times = 1, 
                                  p = 0.1, list = FALSE)
train_set <- edx[-test_index,]
temp <- edx[test_index,]

# Matching userId and movieId in both train and test sets
test_set <- temp %>%
  semi_join(train_set, by = "movieId") %>%
  semi_join(train_set, by = "userId")

# Adding rows back into train set
removed <- anti_join(temp, test_set)
train_set <- rbind(train_set, removed)

rm(test_index, temp, removed)
```

# Data Exploration
First, before engaging in any training of the data, I first had to take a 
closer look at the dataset that was provided. To do this, I outputted some 
summary statistics, and visualized the data so that I could better understand 
the data contained within the dataset.

## Statistical Summary
```{r}
# Statistical summary of the dataset edx
summary(edx)
```
The summary() function provided a statistical summary of the data contained 
within the dataset, which helped me look at the data with a new perspective.

## Unique Users Versus Unique Movies
```{r}
# Output number of users versus number of movies
summarize(edx, num_users = n_distinct(userId), num_movies = n_distinct(movieId))
```
As can be observed, there are 69878 unique users and 10677 unique movies within 
the edx dataset.

## Top Movies Graph
```{r}
# Graph top movies
edx %>%
  group_by(title) %>%
  summarize(count = n()) %>%
  top_n(10, count) %>%
  arrange(-count) %>%
  ggplot(aes(count, reorder(title, count))) +
  geom_bar(color = "gray", fill = "firebrick", stat = "identity") +
  labs(x = "Count", y = "Movies", caption = "Source: edx dataset") +
  ggtitle("Most Popular Movies")
```
This graph is of the top 10 most popular movies within the dataset.

## Number of Ratings Per Rating Graph
```{r}
# Graph number of ratings per rating
edx %>%
  ggplot(aes(rating)) +
  geom_bar(color = "gray", fill = "firebrick") +
  labs(x = "Ratings", y = "Frequency", caption = "Source: edx dataset") +
  scale_x_continuous(breaks = seq(0, 5, by = 0.5)) +
  ggtitle("Rating Count Per Rating")
```
Within this graph, one can observe that no user has given 0 as a rating, and
whole-star ratings are much more common than half-star ratings.

## Number of Ratings Versus Users Graph
```{r}
# Graph number of ratings versus users
edx %>% 
  group_by(userId) %>%
  summarize(count = n()) %>%
  ggplot(aes(count)) +
  geom_histogram(color = "gray", fill = "firebrick", bins = 50) +
  labs(x = "Ratings", y = "Users", caption = "Source: edx dataset") +
  ggtitle("Number of Ratings Versus Users") +
  scale_x_log10()
```
Looking at this graph, one can observe that the graph is skewed to the right.
This indicates that most users are not as active, but there are a few users 
that are much more active than the others.

## Number of Ratings Versus Movies Graph
```{r}
# Graph number of ratings versus movies
edx %>% 
  group_by(movieId) %>%
  summarize(count = n()) %>%
  ggplot(aes(count)) +
  geom_histogram(color = "gray", fill = "firebrick", bins = 50) +
  labs(x = "Ratings", y = "Movies", caption = "Source: edx dataset") +
  ggtitle("Number of Ratings Versus Movies") +
  scale_x_log10()
```
Compared to the Rating Versus Users graph, this graph is much more normally
distributed. Still, one can observe that some movies get rated much more often
than others.

# Data Analysis
With the data exploration finished, it was time to start on the actual data
analysis and training. During this time, I trained 7 models in total, each one 
bringing the overall quality of the model closer to the ideal RMSE defined at
the start of the project.

## RMSE and Mean
To start the data analysis, I made a function that would calculate the RMSE so
that I would not have to calculate it manually every time I created a new 
model.

```{r}
# Function to calculate RMSE
rmse <- function(true_ratings, predicted_ratings) {
  sqrt(mean((true_ratings - predicted_ratings)^2))
}
```
This is the function mentioned above. It takes in the actual movie ratings and
the movie ratings predicted by the model, and outputs the RMSE of the model.

```{r}
# Mean of all ratings
mean_rating <- mean(train_set$rating)
mean_rating
```
As a baseline, I calculated the mean of all the ratings in the training set. 
This was then used to train the first model.

```{r}
# RMSE calculated with just the mean
mean_rmse <- rmse(test_set$rating, mean_rating)
mean_rmse
```
This first model was trained using simply the mean of the training set. 
Because the RMSE is above 1, this is not a very good model, and needs to be 
improved upon in later models.

## Adding Bias to Calculations
Once I established a starting point for my future models to improve on, I 
could implement various changes and fixes that would decrease the RMSE further 
in order to bring myself closer to the goal set previously. Therefore, I 
decided to account for the various biases that can exist in the ratings of 
movies.

### Adding Movie Bias
As can be seen through experience, some types of movies are more popular than 
others. Therefore, I have added this bias into the next model trained.

```{r}
# Add movie bias to calculation
bi <- train_set %>%
  group_by(movieId) %>%
  summarize(b_i = mean(rating - mean_rating))
predicted_ratings <- mean_rating + test_set %>%
  left_join(bi, by = "movieId") %>%
  pull(b_i)
```

```{r}
# RMSE calculated with mean and movie bias
movie_bias_rmse <- rmse(predicted_ratings, test_set$rating)
movie_bias_rmse
```
As can be observed, adding movie bias to the model decreased the RMSE below 1. 
This can be built upon in future models.

### Adding User Bias

```{r}
# Add user bias to calculation
bu <- train_set %>%
  left_join(bi, by = "movieId") %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - mean_rating - b_i))
predicted_ratings <- test_set %>%
  left_join(bi, by = "movieId") %>%
  left_join(bu, by = "userId") %>%
  mutate(pred = mean_rating + b_i + b_u) %>%
  pull(pred)
```

```{r}
# RMSE calculated with mean, movie, and user bias
user_bias_rmse <- rmse(predicted_ratings, test_set$rating)
user_bias_rmse
```

### Adding Time Bias
```{r}
# Add time bias to calculation
bt <- train_set %>%
  mutate(date = round_date(as_datetime(timestamp), unit = "week")) %>%
  left_join(bi, by = "movieId") %>%
  left_join(bu, by = "userId") %>%
  group_by(date) %>%
  summarize(b_t = mean(rating - mean_rating - b_i - b_u))
predicted_ratings <- test_set %>%
  mutate(date = round_date(as_datetime(timestamp), unit = "week")) %>%
  left_join(bi, by = "movieId") %>%
  left_join(bu, by = "userId") %>%
  left_join(bt, by = "date") %>%
  mutate(pred = mean_rating + b_i + b_u + b_t) %>%
  pull(pred)
```

```{r}
# RMSE calculated with mean, movie, user, and time bias
time_bias_rmse <- rmse(predicted_ratings, test_set$rating)
time_bias_rmse
```

## Data Regularization

```{r}
# Applying data regularization
lambdas <- seq(0, 10, 0.25)
rmses <- sapply(lambdas, function(x){
  b_i <- train_set %>%
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mean_rating)/(n() + x)) # adding movie bias
  b_u <- train_set %>%
    left_join(b_i, by = "movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - 
                          mean_rating)/(n() + x)) # adding user bias
  b_t <- train_set %>%
    mutate(date = round_date(as_datetime(timestamp), unit = "week")) %>%
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    group_by(date) %>%
    summarize(b_t = mean(rating - b_i - b_u - 
                           mean_rating)/(n() + x)) # adding time bias
  predicted_ratings <- test_set %>%
    mutate(date = round_date(as_datetime(timestamp), unit = "week")) %>%
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    left_join(b_t, by = "date") %>%
    mutate(pred = mean_rating + b_i + b_u + b_t) %>%
    pull(pred)
  return(rmse(predicted_ratings, test_set$rating))
})
```

```{r}
# Plotting lambdas versus RMSEs
qplot(lambdas, rmses, color = I("red"))
```

```{r}
# Finding which lambda has the lowest RMSE
lambda <- lambdas[which.min(rmses)]
lambda
```

```{r}
# Selecting the lambda with the lowest RMSE
regularized_rmse <- min(rmses)
regularized_rmse
```

## Matrix Factorization (using the recosystem package)

```{r}
# Applying matrix factorization using the recosystem package
if(!require(recosystem)) install.packages(
  "recosystem", repos = "http://cran.us.r-project.org")
library(recosystem)
set.seed(1, sample.kind = "Rounding") # using R 3.6 or later
reco_train <- with(train_set, data_memory(user_index = userId, 
                                          item_index = movieId, 
                                          rating = rating))
reco_test <- with(test_set, data_memory(user_index = userId, 
                                        item_index = movieId, rating = rating))
reco <- Reco()

reco_para <- reco$tune(reco_train, opts = list(dim = c(20, 30), 
                                               costp_l2 = c(0.01, 0.1),
                                               costq_l2 = c(0.01, 0.1), 
                                               lrate = c(0.01, 0.1),
                                               nthread = 4, niter = 10))

reco$train(reco_train, opts = c(reco_para$min, nthread = 4, niter = 30))
reco_first <- reco$predict(reco_test, out_memory())
```

```{r}
# RMSE calculated with matrix factorization
factorization_rmse <- RMSE(reco_first, test_set$rating)
factorization_rmse
```

## Final Holdout Test

```{r}
# Using matrix factorization on final holdout test
set.seed(1, sample.kind = "Rounding") # using R 3.6 or later
reco_edx <- with(edx, data_memory(user_index = userId, item_index = movieId, 
                                  rating = rating))
reco_final_holdout <- with(final_holdout_test, data_memory(user_index = userId, 
                                                           item_index = movieId, 
                                                           rating = rating))
reco <- Reco()

reco_para <- reco$tune(reco_edx, opts = list(dim = c(20, 30), 
                                             costp_l2 = c(0.01, 0.1),
                                             costq_l2 = c(0.01, 0.1), 
                                             lrate = c(0.01, 0.1),
                                             nthread = 4, niter = 10))

reco$train(reco_edx, opts = c(reco_para$min, nthread = 4, niter = 30))
reco_final <- reco$predict(reco_final_holdout, out_memory())
```

```{r}
# Generating final RMSE
final_rmse <- RMSE(reco_final, final_holdout_test$rating)
final_rmse
```

# Final Results

```{r}
# Table made using the reactable package
if(!require(reactable)) install.packages("reactable", 
                                         repos = "http://cran.us.r-project.org")
library(reactable)
if(!require(webshot2)) install.packages("webshot2", 
                                         repos = "http://cran.us.r-project.org")
library(webshot2)
if(!require(htmlwidgets)) install.packages("htmlwidgets", 
                                        repos = "http://cran.us.r-project.org")
library(htmlwidgets)
Methods <- c("Just the mean", "Mean and movie bias", 
             "Mean, movie, and user bias", "Mean, movie, user, and time bias", 
             "Regularized movie, user, and time effects",
             "Matrix factorization using recosystem", 
             "Final holdout test 
             (generated using matrix factorization)") # first column
RMSE <- c(round(mean_rmse, 7), round(movie_bias_rmse, 7), 
          round(user_bias_rmse, 7), round(time_bias_rmse, 7), 
          round(regularized_rmse, 7), round(factorization_rmse, 7), 
          round(final_rmse, 7)) # second column
final_results <- data.frame(Methods, RMSE)
table <- reactable(final_results,
  highlight = TRUE,
  bordered = TRUE,
  theme = reactableTheme(
    borderColor = "#dfe2e5",
    highlightColor = "#f0f5f9",
    cellPadding = "8px 12px",
    style = list(fontFamily = "-apple-system, BlinkMacSystemFont, 
                 Segoe UI, Helvetica, Arial, sans-serif"),
    )
  )
saveWidget(widget = table, file = "table_html.html", selfcontained = TRUE)
webshot(url = "table_html.html", file = "final_table.png", delay = 0.1, 
        vwidth = 1245)
```

# Conclusion